{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06ecdcef-5e8b-4298-9aad-18aa5076ec1e",
   "metadata": {},
   "source": [
    "# **Introduction to Chatbots**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c95a628-fcf6-4304-a2b3-ea00ab52c45e",
   "metadata": {},
   "source": [
    "### What is Chatbot?\n",
    "Chatbots are consersational programs that automate interactions. They are artificial intelligence (A.I) softwares designed to simulate conversation with human users typically through text or voice.\n",
    "\n",
    "- **Examples**:\n",
    "    - A chatbot on a bank's website that helps with enquires\n",
    "    - A chatbot on an e-commerce site that tracks orders or provides recommendations\n",
    "    - Virtual Assistants like **Siri** and **Alexa**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76590092-2a5f-4858-8003-b4e9581c34a2",
   "metadata": {},
   "source": [
    "### B. Difference Between Chatbots and Bots\n",
    "\n",
    "**Chatbots** are a sunset of bots. They are specifically designeed for conversation, meaning they are programmed to interact using natural language processing (NLP) to simulate human conversations.\n",
    "\n",
    "\n",
    "**Bots**, on the other hand are more general-purpose programs designed to automate tasks. They don't necessarily interact, but they perform specific functions like web scraping, sending reminders or managing social media post.\n",
    "\n",
    "- **Chatbot**: Focuses on conversation(e.g., answering customer queries).\n",
    "- **Bot**: Focuses on automating repetitive tasks(e.g; posting scheduled tweets)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2783832b-e582-4e62-bcf4-5de79b85c04e",
   "metadata": {},
   "source": [
    "### C. Tpyes of Chatbots\n",
    "**1. Rule-Based Chatbots**: \n",
    "- They follow specific set of instructions or rules. It works by looking for specific keywords or patterns in what you say and then picking the correct response from its list.\n",
    "- The problem is if you ask something it wasn't programmed for, it might get confused or give a response that doesn't make sense.\n",
    "\n",
    "**2. Retrieval-Based Chatbots**:\n",
    "- They are bit smater than rule-based ones. Instead of giving fixed reply, they search through a bunch of pre-written reponses and try to find the best one based on what you said. It's like going through a library to find the book that mostly answers your question\n",
    "\n",
    "**- Techniques Used**: \n",
    "  - Jaccard Similarity: Imagine you ask question like, \"What's the weather today?\" The bot checks which of its stored answers have the most words in common with your question. The more words they share, the more likely it is to pick that answer.\n",
    "  - Cosine Similarity: This is like comparing two texts using math. It turns your words into numbers and checks how similar they are. If the numbers line up, the bot figures that the answer might be a good fit.\n",
    "  - **Machine Learning Models like `Naive Bayes`**: This is where the bot starts to guess what you're talking about, learning from past examples. If it's trained to answer questions about sports, it'll know that when you ask about \"Football\", it should probably give a sports-related response.\n",
    "\n",
    "\n",
    "**3. Generative Chatbots**:\n",
    "- They are the most advanced chatbots. Instead of pulling from a list of pre-written answers, they create their own reponses based on what you said. It's like having a conversation with someone who thinks on the spot and makes up their answers.\n",
    "- However, they need a lot of training to get good at answering questions. They use models like RNNs, LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f3874f-8448-47b3-8c52-18a4d3d0e2f9",
   "metadata": {},
   "source": [
    "## An example illustrating rule-based, retrieval-based and generative chatbots using a simple customer service scenario related to order tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab42a606-2a84-469b-a994-908152609d93",
   "metadata": {},
   "source": [
    "Scenario\n",
    "\n",
    "The user asks: \"Where is my order?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f2ae64-b538-4d6b-bd22-2e2d6857e09d",
   "metadata": {},
   "source": [
    "**1. Rule-Based Chatbot Example:**\n",
    "- In a rule-based chatbot, predefined keywords like \"order\" and \"track\" to trigger specific responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e343720b-7707-4c16-918b-3da5f3a01556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How may I help you where is my order?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your order number to track your order.\n"
     ]
    }
   ],
   "source": [
    "# Define a function for a simple rule-based chatbot\n",
    "def rule_based_chatbot(user_input):\n",
    "    # Check if the user input contain the words \"track\" or \"order\"\n",
    "    if \"track\" in user_input.lower() or \"order\" in user_input.lower():\n",
    "        # Respond with a prompt to provide an order number\n",
    "        return \"Please provide your order number to track your order.\"\n",
    "\n",
    "    elif \"refund\" in user_input.lower():\n",
    "        # Respond with information about the refund policy\n",
    "        return \"For a refund, please visit our refund policy page.\"\n",
    "\n",
    "    # If the input doesn't match any of the predefined rules \n",
    "    else:\n",
    "        # Reponse with a message indicating the chatbot doesn't understand the query\n",
    "        return \"I'm sorry, I didn't understand that. Can you try again?\"\n",
    "\n",
    "\n",
    "# Example user input \n",
    "user_query = input(\"How may I help you\")\n",
    "\n",
    "print(rule_based_chatbot(user_query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65faad71-2c49-484a-9c0c-c338fff58fa9",
   "metadata": {},
   "source": [
    "## 2. Retrieval-Based Chatbot Example (Jaccard Similarity):**\n",
    "\n",
    "- In a retrieval-based chatbot, the bot looks for similar sentences in a predefined set of responses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c443b1bb-162d-4831-8107-db1a6a2366d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\St\n",
      "[nltk_data]     Mary\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20e98524-52b8-49a7-801d-45fc2ab7310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How may I help you? \n",
      " where is my order\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your order number to track your order.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "\n",
    "# A predefined set of possible responses for the chatbot stored as a list\n",
    "responses = [\n",
    "    \"Please provide your order number to track your order.\",\n",
    "    \"For a refund, please visit our refund policy page.\",\n",
    "    \"Our customer service is available 24/7\"\n",
    "\n",
    "]\n",
    "\n",
    "# Load a set of English stopwords (common words that may be removed in text preprocessing)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define prepeoces funtion to clean and prepare text data\n",
    "def preprocess(text):\n",
    "    # Tokenize the input text into individual words and convert them to lowercase\n",
    "    words = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stopwords (e.g 'the', 'is') and punctuations\n",
    "    words = [word for word in words if word not in stop_words and word not in string.punctuation]\n",
    "\n",
    "    # Return the cleaned list of words\n",
    "    return words\n",
    "\n",
    "# Define Function to calculate Jaccard similarity between two sentences\n",
    "def jaccard_similarity(query, sentence):\n",
    "    # Preprocess the query and the sentence\n",
    "    query_set = set(preprocess(query))\n",
    "    sentence_set = set(preprocess(sentence))\n",
    "\n",
    "    # Calculate the intersection and union of the sets and return Jaccard similarity score\n",
    "    return len(query_set.intersection(sentence_set)) / len(query_set.union(sentence_set))\n",
    "\n",
    "\n",
    "# Define function to find the most relevant response based on user input\n",
    "\n",
    "def retrieval_based_chatbot(user_input): \n",
    "    best_response = \"\" # Placeholder for the best matching response\n",
    "    highest_similarity = 0\n",
    "\n",
    "    # Loop through each predefined response and calculate the Jaccard similarity\n",
    "    for response in responses:\n",
    "        similarity = jaccard_similarity(user_input, response)\n",
    "\n",
    "        # Update the best response if the current respone has a higher similarity score\n",
    "        if similarity > highest_similarity:\n",
    "            highest_similarity = similarity\n",
    "            best_response = response\n",
    "\n",
    "    # Return the best reponse\n",
    "    return best_response if best_response else \"I'm sorry, I couldn't find a relevant response.\"\n",
    "\n",
    "# User Input\n",
    "user_query = input(\"How may I help you? \\n\")\n",
    "\n",
    "print(retrieval_based_chatbot(user_query)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd801ab-cdeb-46ab-ab1a-188c8221dc6d",
   "metadata": {},
   "source": [
    "## Generative Chatbot\n",
    "\n",
    "In a generative chatbot, the response is generated dynamically using a machine learning model (like GPT). This would involve training  a deep learning model.\n",
    "\n",
    "- How it works: The generative chatbot creates a new response based on the user input, generating an original sentence that wasn't pre-programmed or retrieved a predefined list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf4350e-800c-4d8f-aad7-dad4d14aa408",
   "metadata": {},
   "source": [
    "# **D. Common Terms in Natural Language Processing (NLP)**\n",
    "\n",
    "#### 1. Natural Language Processing (NLP)\n",
    "NLP is a ways for computers to understand, interpret, and respond to human language. With NLP, computers can read, listen and even reply like  humans.\n",
    "\n",
    "#### 2. Tokenization\n",
    "Tokenization is breaking down a sentence into smaller pieces that a computer can understand.\n",
    "\n",
    "#### 3. **Lemmatization**\n",
    "Lemmatization is when the computer changes word to their simplest form, called the **Lemma**. For example, the word \"running\" Changes to \"run\"\n",
    "\n",
    "#### 4. **Stemming**\n",
    "Stemming is when the computer cuts off the ends of words to get the base form, or **stem**. For example, \"Playing\", \"Played\", and \"Played\" all become \"Play\". This is different from lemmatization because it chops off word endings. Stemming helps computers group words with similar meanings together by choppings off extra endings.#\n",
    "\n",
    "### 5. **Stopwords**\n",
    "Stopwords are very common words, like \"the\", \"is\", \"and\", \"in\" that computers often ignore when analyzing a sentence\n",
    "\n",
    "\n",
    "### 6. **Corpus**\n",
    "A **Corpus** is a large collection of written or spoken text that computers use to learn and analyze language. It's like giving the computer lots of books to read and study from.\n",
    "\n",
    "### 7. **Bag of Words (BOW)**\n",
    "Is a simple way for computers to represent text. It works by counting how many times each words appears in a text, without caring about the order of the words.\n",
    "\n",
    "### 8. **TF-IDF (Term Frequency-Inverse Document Frequency)**\n",
    "TF-IDF is a more advanced version of **Bag of Words**. It doesn't just count how often a word appears in a text (like BOW), it also checks how rare or important that word is across many documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f1a49d-6ada-46b5-962e-b7516c73ddb3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3358272-743e-46cc-908d-65be4fab4daa",
   "metadata": {},
   "source": [
    "## **E. Workflow for Building a Simple Chatbot using NLTK (Natural Language ToolKit)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "119d1e9b-2b48-4a13-a1f0-dffa11294694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install NLTK and Download all necessary resources\n",
    "# !pip install nltk\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt_tab')\n",
    "\n",
    "# Alternatively\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57c16a7-88a9-46f2-9796-d2b6f04a8453",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "734dcabc-bd99-4998-885d-478f58f8ee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the alice_in_wonderland.txt file\n",
    "\n",
    "with open(\"alice_in_wonderland.txt\", 'r', encoding='utf-8') as f:\n",
    "    text = f.read().replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dbd757-024a-4cf7-bc60-8b0773af997b",
   "metadata": {},
   "source": [
    "## Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25d96626-3ded-46f6-b447-ba19f59a115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "\n",
    "\n",
    "# Initialize stopwords and Lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Use a function for preprocessing each sentence\n",
    "def preprocess(sentence):\n",
    "    tokens = word_tokenize(sentence.lower())\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "# Tokenize text into sentences\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "corpus = [preprocess(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d250b79-f625-4fda-a860-9d0508e44e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement Jaccard Similarity for Response Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86b569f3-005d-45ff-99d1-1c14132a267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function to calculate Jaccard similarity between two sentences\n",
    "def jaccard_similarity(query, sentence):\n",
    "    # Preprocess the query and the sentence\n",
    "    query_set = set(preprocess(query))\n",
    "    sentence_set = set((sentence))\n",
    "\n",
    "    # Calculate the intersection and union of the sets and return Jaccard similarity score\n",
    "    return len(query_set.intersection(sentence_set)) / len(query_set.union(sentence_set))\n",
    "\n",
    "def get_response(query):\n",
    "    max_similarity = 0\n",
    "    best_response = ''\n",
    "\n",
    "    for num, sentence in enumerate(corpus):\n",
    "        similarity = jaccard_similarity(query, sentence)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_response = sentences[num]\n",
    "        return best_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01a40019-2a4f-441c-860d-22d83e24732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What can I help you with? \n",
      " who does Alice meet first in wonderland?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿The Project Gutenberg eBook of Alice's Adventures in Wonderland      This ebook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever.\n"
     ]
    }
   ],
   "source": [
    "user_query = input(\"What can I help you with? \\n\")\n",
    "response = get_response(user_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb1489-2868-472a-a0a2-c891380494ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
